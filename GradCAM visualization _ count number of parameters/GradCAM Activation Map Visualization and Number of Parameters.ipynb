{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91506c8a",
   "metadata": {},
   "source": [
    "# GradCAM Activation Map Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf27b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python cam.py --image-path \"./test_play_1stframe.png\" --use-cuda"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4285d3",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c08f624f",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea3000d",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0b35a8a",
   "metadata": {},
   "source": [
    "# Count number of parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e123c90c",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781b9d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141d5153",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_grad_cam import GradCAM, HiResCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
    "from torchvision.models import resnet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e858527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import models, transforms, utils\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "from PIL import Image\n",
    "import json\n",
    "%matplotlib inline\n",
    "\n",
    "import pytorchvideo\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
    "# from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "# import ResNet\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import urllib\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_loader import VideoDataset\n",
    "# from Utils import do_epoch\n",
    "from Utils.metric import *\n",
    "# from Utils.utility import *\n",
    "\n",
    "import myutils\n",
    "\n",
    "from torchvideotransforms import video_transforms, volume_transforms\n",
    "\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    AugMix,\n",
    "    create_video_transform\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    Lambda,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTensor\n",
    ")\n",
    "\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73653c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f214b236",
   "metadata": {},
   "source": [
    "### Load the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4938479",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.attn_1 = nn.Linear(feature_dim, feature_dim)\n",
    "        self.attn_2 = nn.Linear(feature_dim, 1)\n",
    "\n",
    "        # inititalize\n",
    "        nn.init.xavier_uniform_(self.attn_1.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_2.weight)\n",
    "        self.attn_1.bias.data.fill_(0.0)\n",
    "        self.attn_2.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is encoder output\n",
    "        return_attention decides whether to return\n",
    "        attention scores over the hidden states\n",
    "        \"\"\"\n",
    "#         frame_length = x.shape[1]\n",
    "\n",
    "        self_attention_scores = self.attn_2(torch.tanh(self.attn_1(x)))\n",
    "        \n",
    "        return self_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb7df24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to change this class if want to load the trained model with attention module\n",
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = 2\n",
    "        pretrained = True\n",
    "        self.rnn_hidden_size = 60\n",
    "        rnn_num_layers = 1\n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)  \n",
    "        num_features = baseModel.fc.in_features\n",
    "        baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1))\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "        \n",
    "        self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers)\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size*20, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            output = torch.cat((output.view(b_z,-1,self.rnn_hidden_size), out.view(b_z,-1,self.rnn_hidden_size)), dim=1)\n",
    "\n",
    "        \n",
    "        final_out = self.fc1(output.view(b_z,-1)) \n",
    "        \n",
    "        return final_out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40f3f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model={\n",
    "        \"num_classes\": 2,\n",
    "#         \"dr_rate\": 0.2,\n",
    "        \"pretrained\" : True,\n",
    "        \"rnn_num_layers\": 1,\n",
    "        \"rnn_hidden_size\": 60,\n",
    "        \"attention\": False}\n",
    "model = Resnt34LSTM(params_model)  \n",
    "model = model.to(device)\n",
    "\n",
    "# criterion / loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint = torch.load(\"D:/0_Graduation Thesis/models/weights/Resnet34_LSTM60_MAXpool_WS_OS_allHS_20220530_best_accuracy.pt\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f323e776",
   "metadata": {},
   "source": [
    "### Counting starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8701e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting function\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        params = parameter.numel()\n",
    "        table.add_row([name, params])\n",
    "        total_params+=params\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf18a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c185323b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rn50 = models.resnet50(pretrained=True)\n",
    "# count_parameters(rn50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d40b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting sum in one line\n",
    "sum(dict((p.data_ptr(), p.numel()) for p in model.parameters()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977cdf55",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6cb0c49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41791c1c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d447a67",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
