{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d86f4b1b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f111227",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorchvideo\n",
    "from torchvision.datasets.video_utils import VideoClips\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, WeightedRandomSampler, TensorDataset\n",
    "# from torchsampler import ImbalancedDatasetSampler\n",
    "\n",
    "# import ResNet\n",
    "\n",
    "import cv2\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import urllib\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from data_loader import VideoDataset\n",
    "# from Utils import do_epoch\n",
    "from Utils.metric import *\n",
    "# from Utils.utility import *\n",
    "\n",
    "import myutils\n",
    "\n",
    "from torchvideotransforms import video_transforms, volume_transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ce6f66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388e0bf2",
   "metadata": {},
   "source": [
    "## Import data and transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccb03983",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from torchvision import models\n",
    "\n",
    "# from torchvision.transforms._transforms_video import (\n",
    "#     CenterCropVideo,\n",
    "#     NormalizeVideo,\n",
    "# )\n",
    "\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    Normalize,\n",
    "    RandomShortSideScale,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    AugMix,\n",
    "    create_video_transform\n",
    ")\n",
    "\n",
    "from torchvision.transforms import (\n",
    "    Compose,\n",
    "    RandomCrop,\n",
    "    RandomHorizontalFlip,\n",
    "    ToTensor\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e053482f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# set seed\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)\n",
    "# torch.backends.cudnn.benchmark = False\n",
    "# torch.backends.cudnn.deterministic = True #turning this on might result in CNN underfitting?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d649d231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5d840d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256\n",
    "crop_size = 224\n",
    "num_frames = 20\n",
    "frames_per_second = 30\n",
    "epochs = 500\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb71a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT IN USE\n",
    "# train_transform = create_video_transform(num_samples=num_frames, max_size=side_size, crop_size=crop_size, mode='train')\n",
    "# test_transform = create_video_transform(num_samples=num_frames, max_size=side_size, crop_size=crop_size, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f0fa038",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "video_transforms.Resize kind of perform scaling based on shorter side.\n",
    "'''\n",
    "\n",
    "train_transform = Compose([\n",
    "            video_transforms.Resize((side_size, side_size)),\n",
    "            video_transforms.CenterCrop(crop_size),\n",
    "            volume_transforms.ClipToTensor(),\n",
    "            UniformTemporalSubsample(num_frames)\n",
    "            ])\n",
    "\n",
    "\n",
    "test_transform = Compose([\n",
    "            video_transforms.Resize((side_size, side_size)),\n",
    "            video_transforms.CenterCrop(crop_size),\n",
    "            volume_transforms.ClipToTensor(),\n",
    "            UniformTemporalSubsample(num_frames)\n",
    "            ])  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b3cc1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train size: 3304\n",
      "test size: 826\n",
      "robust test size: 203\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv('train_final.csv')\n",
    "test_df = pd.read_csv('test1_final.csv')\n",
    "robust_df = pd.read_csv('test2_final.csv')\n",
    "print(\"train size:\", len(train_df))\n",
    "print(\"test size:\", len(test_df))\n",
    "print(\"robust test size:\", len(robust_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e43b530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfor downsampling\\n'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Weighted sampling\n",
    "'''\n",
    "# # class weighting based on binary label\n",
    "labels_unique, counts = np.unique(train_df['label'], return_counts=True)\n",
    "class_weights = [sum(counts) / c for c in counts]\n",
    "\n",
    "# # assign weight to each input sample (based on binary label)\n",
    "sample_weights = [class_weights[i] for i in train_df['label']]\n",
    "\n",
    "\n",
    "g = torch.Generator()\n",
    "g.manual_seed(42)\n",
    "\n",
    "\n",
    "# # weighted sampling without oversample/downsample\n",
    "# train_sampler = WeightedRandomSampler(sample_weights, len(train_df))\n",
    "\n",
    "\n",
    "# oversampling\n",
    "train_sampler = WeightedRandomSampler(sample_weights, len(train_df['label']) + (len(train_df[train_df['label']==0]) - len(train_df[train_df['label']==1])), generator=g)\n",
    "\n",
    "# # downsampling\n",
    "# train_sampler = WeightedRandomSampler(sample_weights, len(train_df[train_df['label']==1])*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "372175eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clip_base_path = 'D:/Dataset_BENG/short_clips/all_short_clips'\n",
    "train_dataset = VideoDataset(video_clip_path=os.path.join(clip_base_path, 'train_final.pkl'), dataframe=train_df, video_transform=train_transform)\n",
    "test_dataset = VideoDataset(video_clip_path=os.path.join(clip_base_path, 'test1_final.pkl'), dataframe=test_df, video_transform=test_transform)\n",
    "robust_dataset = VideoDataset(video_clip_path=os.path.join(clip_base_path, 'test2_final.pkl'), dataframe=robust_df, video_transform=test_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4b9d6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# oversampling only for train data loader\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, pin_memory=True, num_workers=6, drop_last=False)\n",
    "# train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, pin_memory=True, num_workers=6, drop_last=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6, drop_last=False)\n",
    "robust_test_loader = DataLoader(robust_dataset, batch_size=batch_size, shuffle=False, pin_memory=True, num_workers=6, drop_last=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f11af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "view the video frame\n",
    "'''\n",
    "plt.imshow(train_loader.dataset[831][0][0].permute(1,2,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "820a8fb8",
   "metadata": {},
   "source": [
    "# Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c2a2789",
   "metadata": {},
   "source": [
    "### ResNet34-LSTM: Predict at every frame\n",
    "**flattening vs. global avg pooling vs. global max pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4dc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = params_model[\"num_classes\"]\n",
    "#         dr_rate= params_model[\"dr_rate\"]\n",
    "        pretrained = params_model[\"pretrained\"]\n",
    "        self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "        rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "        attention = params_model[\"attention\"]\n",
    "        \n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)\n",
    "\n",
    "        '''\n",
    "        # as feature extractor, no finetuning during backpropogation\n",
    "#         for param in baseModel.parameters():\n",
    "#             param.requires_grad = False\n",
    "        '''        \n",
    "\n",
    "\n",
    "        num_features = baseModel.fc.in_features\n",
    "#         baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1)) # uncomment this for GLOBAL MAX POOLING\n",
    "#         baseModel.avgpool = Identity() # uncomment this for GLOBAL AVG POOLING\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "#         self.dropout= nn.Dropout(dr_rate)\n",
    "#         self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers) # uncomment this for GLOBAL MAX & AVG POOLING\n",
    "        self.rnn = nn.LSTM(25088, self.rnn_hidden_size, rnn_num_layers) # uncomment this for flattening\n",
    "        \n",
    "        # prediction at every frame\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size, 1)\n",
    "        self.fc2 = nn.Linear(20, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        \n",
    "        \n",
    "        # prediction at every frame\n",
    "        rnn_pred_cat = self.fc1(output.view(b_z, -1))\n",
    "        \n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            \n",
    "            # prediction at every frame\n",
    "            rnn_pred = self.fc1(out.view(b_z, -1))\n",
    "            rnn_pred_cat = torch.cat((rnn_pred_cat, rnn_pred), dim=1)\n",
    "    \n",
    "               \n",
    "        # prediction at every frame\n",
    "        final_out = self.fc2(rnn_pred_cat.view(b_z, -1))\n",
    "   \n",
    "        return final_out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0606060",
   "metadata": {},
   "source": [
    "### ResNet34-LSTM: Predict using LAST HIDDEN STATE\n",
    "**flattening vs. global avg pooling vs. global max pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05c6f038",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = params_model[\"num_classes\"]\n",
    "#         dr_rate= params_model[\"dr_rate\"]\n",
    "        pretrained = params_model[\"pretrained\"]\n",
    "        self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "        rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "        attention = params_model[\"attention\"]\n",
    "        \n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)    \n",
    "\n",
    "\n",
    "        num_features = baseModel.fc.in_features\n",
    "#         baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1)) # uncomment this for GLOBAL MAX POOLING\n",
    "#         baseModel.avgpool = Identity() # uncomment this for GLOBAL AVG POOLING\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "#         self.dropout= nn.Dropout(dr_rate)\n",
    "#         self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers) # uncomment this for GLOBAL MAX & AVG POOLING\n",
    "        self.rnn = nn.LSTM(25088, self.rnn_hidden_size, rnn_num_layers) # uncomment this for flattening\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        \n",
    "        \n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "\n",
    "\n",
    "        out = self.fc1(out)\n",
    "        final_out = self.fc1(out.view(b_z, -1))\n",
    "        \n",
    "        return final_out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca09686",
   "metadata": {},
   "source": [
    "### ResNet34-LSTM: Predict using ALL HIDDEN STATES (no attention)\n",
    "**flattening vs. global avg pooling vs. global max pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212f0a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = params_model[\"num_classes\"]\n",
    "#         dr_rate= params_model[\"dr_rate\"]\n",
    "        pretrained = params_model[\"pretrained\"]\n",
    "        self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "        rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "        attention = params_model[\"attention\"]\n",
    "        \n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)    \n",
    "\n",
    "        num_features = baseModel.fc.in_features\n",
    "#         baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1)) # uncomment this for GLOBAL MAX POOLING\n",
    "#         baseModel.avgpool = Identity() # uncomment this for GLOBAL AVG POOLING\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "#         self.dropout= nn.Dropout(dr_rate)\n",
    "#         self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers) # uncomment this for GLOBAL MAX & AVG POOLING\n",
    "        self.rnn = nn.LSTM(25088, self.rnn_hidden_size, rnn_num_layers) # uncomment this for flattening\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size*20, 2)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "\n",
    "        \n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            # all hidden states\n",
    "            output = torch.cat((output.view(b_z,-1,self.rnn_hidden_size), out.view(b_z,-1,self.rnn_hidden_size)), dim=1)\n",
    "\n",
    "\n",
    "# output = self.dropout(output.view(b_z, -1))\n",
    "\n",
    "\n",
    "        # prediction using all HS\n",
    "        final_out = self.fc1(output.view(b_z, -1))\n",
    "        \n",
    "        return final_out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daaf9b31",
   "metadata": {},
   "source": [
    "### ResNet34-LSTM: Predict using ALL HIDDEN STATES (WITH attention)\n",
    "**flattening vs. global avg pooling vs. global max pooling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "280562f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Attention module used in LSTM\n",
    "'''\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.attn_1 = nn.Linear(feature_dim, feature_dim)\n",
    "        self.attn_2 = nn.Linear(feature_dim, 1)\n",
    "\n",
    "        # inititalize\n",
    "        nn.init.xavier_uniform_(self.attn_1.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_2.weight)\n",
    "        self.attn_1.bias.data.fill_(0.0)\n",
    "        self.attn_2.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is encoder output\n",
    "        return_attention decides whether to return\n",
    "        attention scores over the hidden states\n",
    "        \"\"\"\n",
    "#         frame_length = x.shape[1]\n",
    "\n",
    "        self_attention_scores = self.attn_2(torch.tanh(self.attn_1(x)))\n",
    "        \n",
    "        return self_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9392d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self, params_model):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = params_model[\"num_classes\"]\n",
    "#         dr_rate= params_model[\"dr_rate\"]\n",
    "        pretrained = params_model[\"pretrained\"]\n",
    "        self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "        rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "        attention = params_model[\"attention\"]\n",
    "\n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)      \n",
    "        num_features = baseModel.fc.in_features\n",
    "#         baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1))\n",
    "        baseModel.avgpool = Identity() #flattening\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "#         self.dropout= nn.Dropout(dr_rate)\n",
    "        if attention:\n",
    "            self.attention = Attention(self.rnn_hidden_size)\n",
    "        \n",
    "#         self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers) # uncomment this for GLOBAL MAX & AVG POOLING\n",
    "        self.rnn = nn.LSTM(25088, self.rnn_hidden_size, rnn_num_layers)\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size*20, num_classes)\n",
    "\n",
    "#     def forward(self, x, coord_seq):\n",
    "    def forward(self, x):        \n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        \n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            output = torch.cat((output.view(b_z,-1,self.rnn_hidden_size), out.view(b_z,-1,self.rnn_hidden_size)), dim=1)\n",
    "\n",
    "       \n",
    "        '''\n",
    "        temporal attention to all hidden states\n",
    "        '''\n",
    "        if self.attention is not None:\n",
    "            out_att_score = self.attention(output)\n",
    "            out_att_score_sftmx = F.softmax(out_att_score, dim=1)\n",
    "            out_agg_att = out_att_score_sftmx * output\n",
    "            final_out = self.fc1(out_agg_att.view(b_z, -1)) #return all attended hidden states\n",
    "\n",
    "        return final_out \n",
    "    \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bfabf20",
   "metadata": {},
   "source": [
    "### VGG16-LSTM (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f4915a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class VGG16LSTM(nn.Module):\n",
    "#     def __init__(self, params_model):\n",
    "#         super(VGG16LSTM, self).__init__()\n",
    "#         num_classes = params_model[\"num_classes\"]\n",
    "# #         dr_rate= params_model[\"dr_rate\"]\n",
    "#         pretrained = params_model[\"pretrained\"]\n",
    "#         self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "#         rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "#         attention = params_model[\"attention\"]\n",
    "        \n",
    "#         baseModel = models.vgg16(pretrained=pretrained)\n",
    "#         num_features = baseModel.classifier[0].in_features\n",
    "#         baseModel.avgpool = Identity()\n",
    "#         baseModel.classifier = Identity()\n",
    "#         self.baseModel = baseModel\n",
    "# #         self.dropout= nn.Dropout(dr_rate)\n",
    "#         self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers)\n",
    "#         self.fc1 = nn.Linear(self.rnn_hidden_size, 1)\n",
    "#         self.fc2 = nn.Linear(20, 2)\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "#         ii = 0\n",
    "#         y = self.baseModel((x[:,ii]))\n",
    "#         output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        \n",
    "#         # prediction for every frame\n",
    "#         rnn_pred_cat = self.fc1(output.view(b_z, -1))\n",
    "        \n",
    "#         for ii in range(1, ts):\n",
    "#             y = self.baseModel((x[:,ii]))\n",
    "#             out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            \n",
    "#             # prediction for every frame\n",
    "#             rnn_pred = self.fc1(out.view(b_z, -1))\n",
    "#             rnn_pred_cat = torch.cat((rnn_pred_cat, rnn_pred), dim=1)\n",
    "\n",
    "#         final_out = self.fc2(rnn_pred_cat.view(b_z, -1))\n",
    "            \n",
    "#         return final_out\n",
    "\n",
    "    \n",
    "# class Identity(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Identity, self).__init__()\n",
    "#     def forward(self, x):\n",
    "#         return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a747d6",
   "metadata": {},
   "source": [
    "### InceptionV3-LSTM (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd71910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class InceptionV3(nn.Module):\n",
    "#     def __init__(self, params_model):\n",
    "#         super(InceptionV3, self).__init__()\n",
    "#         num_classes = params_model[\"num_classes\"]\n",
    "# #         dr_rate= params_model[\"dr_rate\"]\n",
    "#         pretrained = params_model[\"pretrained\"]\n",
    "#         self.rnn_hidden_size = params_model[\"rnn_hidden_size\"]\n",
    "#         rnn_num_layers = params_model[\"rnn_num_layers\"]\n",
    "#         attention = params_model[\"attention\"]\n",
    "        \n",
    "#         baseModel = models.inception_v3(pretrained=pretrained)\n",
    "#         num_features = baseModel.fc.in_features\n",
    "#         baseModel.avgpool = Identity()\n",
    "#         baseModel.dropout = nn.Dropout(0.0)\n",
    "#         baseModel.fc = Identity()\n",
    "#         baseModel.aux_logits = False\n",
    "#         self.baseModel = baseModel\n",
    "# #         self.dropout= nn.Dropout(dr_rate)\n",
    "#         self.rnn = nn.LSTM(131072, self.rnn_hidden_size, rnn_num_layers)\n",
    "#         self.fc1 = nn.Linear(self.rnn_hidden_size, 1)\n",
    "#         self.fc2 = nn.Linear(20, 2)\n",
    "        \n",
    "#     def forward(self, x, coord_seq):\n",
    "#         b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "#         ii = 0\n",
    "#         y = self.baseModel((x[:,ii]))\n",
    "#         output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        \n",
    "#         # prediction for every frame\n",
    "#         rnn_pred_cat = self.fc1(output.view(b_z, -1))\n",
    "        \n",
    "#         for ii in range(1, ts):\n",
    "#             y = self.baseModel((x[:,ii]))\n",
    "#             out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            \n",
    "#             # prediction for every frame\n",
    "#             rnn_pred = self.fc1(out.view(b_z, -1))\n",
    "#             rnn_pred_cat = torch.cat((rnn_pred_cat, rnn_pred), dim=1)\n",
    "\n",
    "#         final_out = self.fc2(rnn_pred_cat.view(b_z, -1))\n",
    "            \n",
    "#         return final_out\n",
    "\n",
    "    \n",
    "# class Identity(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Identity, self).__init__()\n",
    "#     def forward(self, x):\n",
    "#         return x    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d40eccf0",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2501ab1",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff1cbc4",
   "metadata": {},
   "source": [
    "### Model hyperparameters settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36d1b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_model={\n",
    "        \"num_classes\": 2,\n",
    "#         \"dr_rate\": 0.5,\n",
    "        \"pretrained\" : True,\n",
    "        \"rnn_num_layers\": 1,\n",
    "        \"rnn_hidden_size\": 60,\n",
    "        \"attention\": True}\n",
    "model = Resnt34LSTM(params_model)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9065cd0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b837a636",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "# momentum = 0.9\n",
    "\n",
    "# criterion\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# criterion = nn.CrossEntropyLoss(reduction='sum')\n",
    "\n",
    "# optimizer & learning rate schedulers\n",
    "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "lr_schedulers = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.2, patience = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ccab51",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = \"ResNet34_LSTM60_WSOS_flattening_attention\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7fdc23",
   "metadata": {},
   "source": [
    "### Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2df8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date, datetime\n",
    "\n",
    "today = date.today().strftime(\"%Y%m%d\")\n",
    "print(\"Today's date:\"+today)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a964b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log(message):\n",
    "#     with open(os.path.join(args.log_path, args.exp)+'.txt', 'a+') as logger:\n",
    "    with open(\"D:/0_Graduation Thesis/training_log/\"+ today + model_type + '.txt', 'a+') as logger:\n",
    "        logger.write(f'{message}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cf429f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "log(f\"Date:{today}\")\n",
    "log(f\"Model: {model_type}\")\n",
    "log(f\"train set with len: {len(train_dataset)}\")\n",
    "log(f\"test set with len: {len(test_dataset)}\")\n",
    "# log(f\"ROBUST test set with len: {len(robust_dataset)}\\n\")\n",
    "\n",
    "log(f\"Oversample/Undersample training set with len: {train_loader.sampler.num_samples}\\n\")\n",
    "\n",
    "# log(f'Explanation: {args.exp}')\n",
    "# log(f\"Lambda: {args.ld}\")\n",
    "log(f\"Transformation applied on training set: {train_transform}\")\n",
    "log(f\"Resize: {side_size}\")\n",
    "log(f\"Centre crop size: {crop_size}\")\n",
    "# log(f\"Uniform temporal sampled frames: {num_frames}\\n\")\n",
    "\n",
    "log(f\"Device: {device}\")\n",
    "log(f'n_epochs: {epochs}')\n",
    "log(f'batch_size: {batch_size}\\n')\n",
    "log(f\"Optimizer : {optimizer}\")\n",
    "\n",
    "# log(f'num_workers: {args.num_workers}')\n",
    "# log(f'Early Stop Count: {esct}')\n",
    "# log(f\"Optimizer: SGD\")\n",
    "# log(f\"Learning Rate: lr\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264d9a37",
   "metadata": {},
   "source": [
    "## Train & test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5f10c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "params_train={\n",
    "    \"num_epochs\": epochs,\n",
    "    \"optimizer\": optimizer,\n",
    "    \"loss_func\": criterion,\n",
    "    \"train_dl\": train_loader,\n",
    "    \"val_dl\": test_loader,\n",
    "    \"robust_dl\": robust_test_loader,\n",
    "    \"sanity_check\": False,\n",
    "    \"lr_scheduler\": lr_schedulers,\n",
    "    \"path2weights\": \"D:/0_Graduation Thesis/models/weights/\"+model_type+\"_\"+today,\n",
    "    \"esct\": 15,\n",
    "    \"path2cp\": \"D:/0_Graduation Thesis/models/checkpoints/\"+model_type+\"_\"+today\n",
    "    }\n",
    "# model, loss_hist, metric_hist, pred_label_epoch= myutils.train_val(model,params_train,log)\n",
    "model, loss_hist, metric_hist, pred_label_epoch, robust_pred_label = myutils.train_val(model,params_train,log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86f0398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "plot the loss & acc\n",
    "'''\n",
    "myutils.plot_loss(loss_hist, metric_hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32155d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sort the metrics and print\n",
    "'''\n",
    "\n",
    "import math\n",
    "# get sorted accuracy list\n",
    "sorted_acc = sorted([x for x in metric_hist['val_acc'] if not math.isnan(x)])\n",
    "sorted_acc_r = sorted([x for x in metric_hist['robust_acc'] if not math.isnan(x)])\n",
    "\n",
    "# get sorted loss list\n",
    "sorted_loss = sorted([x for x in loss_hist['val'] if not math.isnan(x)])\n",
    "\n",
    "# get sorted MCC list\n",
    "sorted_mcc = sorted([x for x in metric_hist['val_mcc'] if not math.isnan(x)])\n",
    "sorted_mcc_r = sorted([x for x in metric_hist['robust_mcc'] if not math.isnan(x)])\n",
    "\n",
    "print('%.4G / %.4G' % (sorted_loss[0], sorted_loss[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba0dddf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the original index of the element before sorting\n",
    "sorted_acc_index = np.argsort(metric_hist['val_acc'])\n",
    "sorted_loss_index = np.argsort(loss_hist['val'])\n",
    "sorted_auc_index = np.argsort(metric_hist['val_auc'])\n",
    "sorted_mcc_index = np.argsort(metric_hist['val_mcc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc689bb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f55cd21",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45470f2b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336ae986",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73a4b66b",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26fa6884",
   "metadata": {},
   "source": [
    "## Load and run the checkpoint / saved models\n",
    "to check the wrongly predicted cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece457a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import recall_score, roc_auc_score, accuracy_score, precision_score, confusion_matrix, average_precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "41b4e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, feature_dim):\n",
    "        super(Attention, self).__init__()\n",
    "\n",
    "        self.attn_1 = nn.Linear(feature_dim, feature_dim)\n",
    "        self.attn_2 = nn.Linear(feature_dim, 1)\n",
    "\n",
    "        # inititalize\n",
    "        nn.init.xavier_uniform_(self.attn_1.weight)\n",
    "        nn.init.xavier_uniform_(self.attn_2.weight)\n",
    "        self.attn_1.bias.data.fill_(0.0)\n",
    "        self.attn_2.bias.data.fill_(0.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Input x is encoder output\n",
    "        return_attention decides whether to return\n",
    "        attention scores over the hidden states\n",
    "        \"\"\"\n",
    "#         frame_length = x.shape[1]\n",
    "\n",
    "        self_attention_scores = self.attn_2(torch.tanh(self.attn_1(x)))\n",
    "        \n",
    "        return self_attention_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6337dccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resnt34LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Resnt34LSTM, self).__init__()\n",
    "        num_classes = 2\n",
    "        pretrained = True\n",
    "        self.rnn_hidden_size = 60\n",
    "        rnn_num_layers = 1\n",
    "        \n",
    "        baseModel = models.resnet34(pretrained=pretrained)  \n",
    "        num_features = baseModel.fc.in_features\n",
    "        baseModel.avgpool = nn.AdaptiveMaxPool2d(output_size=(1,1))\n",
    "        baseModel.fc = Identity()\n",
    "        self.baseModel = baseModel\n",
    "        self.attention = Attention(self.rnn_hidden_size)\n",
    "        self.rnn = nn.LSTM(num_features, self.rnn_hidden_size, rnn_num_layers)\n",
    "        self.fc1 = nn.Linear(self.rnn_hidden_size*20, num_classes)\n",
    "\n",
    "        \n",
    "    def forward(self, x):        \n",
    "        b_z, ts, c, h, w = x.shape\n",
    "        \n",
    "        \n",
    "        ii = 0\n",
    "        y = self.baseModel((x[:,ii]))\n",
    "        output, (hn, cn) = self.rnn(y.unsqueeze(0))\n",
    "        for ii in range(1, ts):\n",
    "            y = self.baseModel((x[:,ii]))\n",
    "            out, (hn, cn) = self.rnn(y.unsqueeze(0), (hn, cn))\n",
    "            output = torch.cat((output.view(b_z,-1,self.rnn_hidden_size), out.view(b_z,-1,self.rnn_hidden_size)), dim=1)\n",
    "\n",
    "        out_att_score = self.attention(output)\n",
    "        out_att_score_sftmx = F.softmax(out_att_score, dim=1)\n",
    "        out_agg_att = out_att_score_sftmx * output\n",
    "        final_out = self.fc1(out_agg_att.view(b_z, -1))\n",
    "        \n",
    "        \n",
    "        return final_out\n",
    "        \n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0dc93ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Resnt34LSTM(\n",
       "  (baseModel): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (3): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (4): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (5): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (2): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveMaxPool2d(output_size=(1, 1))\n",
       "    (fc): Identity()\n",
       "  )\n",
       "  (attention): Attention(\n",
       "    (attn_1): Linear(in_features=60, out_features=60, bias=True)\n",
       "    (attn_2): Linear(in_features=60, out_features=1, bias=True)\n",
       "  )\n",
       "  (rnn): LSTM(512, 60)\n",
       "  (fc1): Linear(in_features=1200, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Resnt34LSTM()  \n",
    "model = model.to(device)\n",
    "\n",
    "# criterion / loss function\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "checkpoint = torch.load(\"D:/0_Graduation Thesis/models/weights/Resnet34_LSTM60_MAXpool_WSOS_allattendedHS_20220604_best_accuracy.pt\")\n",
    "model.load_state_dict(checkpoint)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a81d11f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics_batch(output, target):\n",
    "    pred = output.argmax(dim=1, keepdim=True)\n",
    "    pred_label = output.argmax(dim=1)\n",
    "    prob = F.softmax(output, dim=1)[:, 1]\n",
    "    corrects=pred.eq(target.view_as(pred)).sum().item()\n",
    "    return corrects, prob, pred_label\n",
    "\n",
    "def loss_batch(loss_func, output, target, opt=None):\n",
    "    loss = loss_func(output, target)\n",
    "    with torch.no_grad():\n",
    "        metric_b, prob_b, pred_label_b = metrics_batch(output,target)\n",
    "    if opt is not None:\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return loss.item(), metric_b, prob_b, pred_label_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "50d7e05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "with torch.no_grad():\n",
    "    running_loss=0.0\n",
    "    running_acc=0.0\n",
    "    len_data = len(robust_test_loader.dataset)\n",
    "\n",
    "    true_label= np.empty(1)\n",
    "    predict_prob= np.empty(1)\n",
    "    pred_label= np.empty(1)\n",
    "\n",
    "    for xb, yb in robust_test_loader:\n",
    "        true_label = np.append(true_label, yb.numpy())\n",
    "\n",
    "        xb=xb.to(device)\n",
    "        yb=yb.to(device)\n",
    "        output=model(xb)\n",
    "        loss_b,acc_b,prob_b,pred_b=loss_batch(criterion, output, yb)\n",
    "        running_loss+=loss_b\n",
    "\n",
    "        predict_prob = np.append(predict_prob, prob_b.cpu().numpy())\n",
    "        pred_label = np.append(pred_label, pred_b.cpu().numpy())\n",
    "\n",
    "        if acc_b is not None:\n",
    "            running_acc+=acc_b\n",
    "\n",
    "    loss=running_loss/float(len_data)\n",
    "    acc=running_acc/float(len_data)\n",
    "\n",
    "    true_label = true_label[1:]\n",
    "    predict_prob = predict_prob[1:]\n",
    "    pred_label = pred_label[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bd8f559a",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_bool = true_label == pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "4cb26e79",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 100)\n",
    "# wrong_df = robust_df[label_bool]\n",
    "correct_df = robust_df[label_bool]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5623d01e",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<br>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
